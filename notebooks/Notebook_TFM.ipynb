{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e3cd3e",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "El notebook de este TFM posee la siguiente estructura, detallada a continuación para su comprensión:\n",
    "- 1. Import Library. Importaciones de Librerías\n",
    "- 2. Import XML. Contiene las funciones necesarias para la lectura del fichero fuente XML de Orphadata, y, a partir de ahí, poder trabajar con los datos.\n",
    "- 3. Exploratory Data Analysis (EDA) & Feature Engineering functions. Funciones asociadas a la Exploración de los datos, limpieza y preparación de los mismos. Contienen la funciones eda_data (más enfocada a \"limpieza\") y selection_data_by_frecuency (donde filtramos por la frecuencia de aparición de un síntoma en una enfermedad concreta).\n",
    "- 4. DATA/MATRIX functions for recommender. Funciones asociadas al Experimento en las que se generan las matrices y listados necesarios para trabajar con un Sistema Recomendador. Contiene las siguientes funciones: \n",
    "        - generate_data_scoring, la cual se encarga generar una matriz de asociación entre un síntoma y una enfermedad\n",
    "        (de acuerdo a la existecia/aparición del síntoma en la enfermedad), dando una puntación (en la casilla \n",
    "        correspondiente de la matriz) a la alineada a la frecuencia estadística de dicha aparecición (muy frecuente, \n",
    "        frecuente,....).\n",
    "        - generate_data_recommendations, la cual se encarga de calcular dos matrices de trabajo .\n",
    "        La primera de similitud entre los síntomas, y la segunda, que guarda en CSV, la de recomendaciones.\n",
    "        Esta última de recomendación será cargada en el momento de calcular una recomendación de enfermedad \n",
    "        dado un síntoma.  Se trabajará con sqlite3 para guardar la matriz de recomendación, y no tener que calcularla \n",
    "        cada vez que queramos hacer una recomendación\n",
    "        - generate_data_enfermedades, la cual genera un listado con todas las enfermedades para trabajar con él\n",
    "        - generate_data_sintomas, la cual genera un listado con todas los síntomas para trabajar con él\n",
    "\n",
    "Hasta este punto hablamos de la fase de procesamiento de información, la cual es identificada en el IDE Kedro (Visual Studio) como  pipeline de data_processing.\n",
    "\n",
    "- 5. Recomendation functions. Funciones asociadas al Experimento en las que se realizan llamadas a los recomendadores trabajados. Contiene las siguientes funciones: \n",
    "        - recommendation_collaborative_filtering_user_based. Función que usa User Based de Collaborative Filtering\n",
    "        para obtener una recomendación.\n",
    "        - recommendation_similitud_by_pearson: Función que usa Correlación de Pearson para obtener una recomendación. \n",
    "        Recibe un Síntoma concreto y devuelve un listado de X enfermedades recomendadas (por scoring de mayor a \n",
    "        menor).\n",
    "   \n",
    "     La recomendación por pearson, la implementamos para ver resultados, comparar ambos algoritmos y verificar que los scorings son similares.\n",
    "\n",
    "\n",
    "Hasta este punto hemos trabajado con las funciones para lanzar recomendaciones. Éstas están incluidas en el pipeline de data_science en el ID Kedro (Visual Studio)\n",
    "\n",
    "- 6. Notebook Main: Common Tasks: Es el MAIN principal del notebook. Contiene las llamadas a las diferentes funciones definidas en el notebook para la obtención de los resultados. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(*) Antes de comenzar con las librerías, tal vez le sea necesario instalar alguna de ellas. Es el caso ydata-profiling. Se adjunta el código para realizar dicha instalación. Utilicese si alguno de los import no le es reconocido y debe instalar, con pip, la librería en cuestión.  Debe reiniciarse el Kernel tras estas instalaciones.\n",
    "\n",
    "!pip install ydata-profiling    \n",
    "\n",
    "(*) no funcionando correctamente con versión matplotlib==3.8.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1663e304",
   "metadata": {},
   "source": [
    "# 1. Import Library\n",
    "Se importan todas las librerías necesarias para trabajar en el presente Notebook para los dos experimentos que contiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2acbb61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from ydata_profiling import ProfileReport\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b56c8b5",
   "metadata": {},
   "source": [
    "# 2. Import XML\n",
    "\n",
    "_limpia_nombre: Función privada, que usa import_enfermedades_xml, para eliminar carácteres innecesarios en los nombres encontrados en el XML fuente (para enfermedades y frecuencias) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca0abbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _limpia_nombre (cadena):\n",
    "    \n",
    "    cadena_str= str(cadena)\n",
    "    cadena_str=cadena_str[26:]\n",
    "    cadena_str = cadena_str.replace('}', '',1)\n",
    "    cadena_str = cadena_str.replace('\\'','')\n",
    "    \n",
    "    return cadena_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d8ba03",
   "metadata": {},
   "source": [
    "import_enfermedades_xml: Función que extrae a un dataframe los datos de Enfermedades-Síntomas-Frecuencias del XML de Orphadata  (almacenado en una ruta concreta). Se encarga de coger el XML y cargar la información de enfermedades-sintomas-frecuencias.\n",
    "Es llamada únicamente al principio para trabajar, pues luego se continua con dataframes y csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a963b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_enfermedades_xml (path):\n",
    "    xml=open(path, encoding='ISO-8859-1')\n",
    "    xmldict = xmltodict.parse(xml.read())\n",
    "    df_enfermedades = pd.DataFrame()\n",
    "    lista_enfer_sinto_prob=[]\n",
    "    first_tree=xmldict[\"JDBOR\"][\"HPODisorderSetStatusList\"][\"HPODisorderSetStatus\"]\n",
    "    id=0\n",
    "    for nodo in xmldict[\"JDBOR\"][\"HPODisorderSetStatusList\"][\"HPODisorderSetStatus\"]:\n",
    "     \n",
    "        enfermedad=_limpia_nombre(nodo[\"Disorder\"][\"Name\"])\n",
    "        sec_tree= nodo[\"Disorder\"][\"HPODisorderAssociationList\"]\n",
    "        if (len(sec_tree)==2):\n",
    "            tam_sintomas=len(sec_tree[\"HPODisorderAssociation\"])\n",
    "            i=0\n",
    "            registro_enfer_sinto_prob=[]\n",
    "            while (i<tam_sintomas):\n",
    "                registro_enfer_sinto_prob.append(id)\n",
    "                registro_enfer_sinto_prob.append(enfermedad)\n",
    "                registro_enfer_sinto_prob.append(sec_tree[\"HPODisorderAssociation\"][i][\"HPO\"][\"HPOTerm\"])\n",
    "                frecuencia=_limpia_nombre (sec_tree[\"HPODisorderAssociation\"][i][\"HPOFrequency\"][\"Name\"])\n",
    "                registro_enfer_sinto_prob.append(frecuencia)\n",
    "                lista_enfer_sinto_prob.append (registro_enfer_sinto_prob)\n",
    "                registro_enfer_sinto_prob=[]\n",
    "                i=i+1\n",
    "        id=id+1\n",
    "    df_enfermedades = pd.DataFrame(lista_enfer_sinto_prob)\n",
    "    df_enfermedades = df_enfermedades.rename(columns={0:'Id_Enfermedad',1:'Enfermedad', 2:'Sintoma', 3:\"Frecuencia\"})\n",
    "    \n",
    "    return df_enfermedades        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeffcef",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis (EDA) & Feature Engineering functions\n",
    "\n",
    "eda_data: Función que dado un dataframe de entrada, aplica Exploratory Data Analysis. En concreto: elimina registros duplicados, los nulos, y los registros que contienen síntomas que sólo aparecen menos de 50 veces en nuestra muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "136d05d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_data(data): \n",
    "    \n",
    "    data=data.drop_duplicates()\n",
    "    data=data.dropna()\n",
    "    vc = data[\"Sintoma\"].value_counts()\n",
    "    vector=vc[vc < 50].index\n",
    "    for a in vector:\n",
    "        indexNames = data [ data[\"Sintoma\"] == a ].index\n",
    "        for b in indexNames:\n",
    "            data.drop(b , inplace=True, axis=0)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169d1233",
   "metadata": {},
   "source": [
    "selection_data_by_frecuency: Función que dado un dataframe de entrada, se queda con los registros de Enfermedad-Sintoma-Frecuencia que tengan una frecuencia \"Muy frecuente\", \"Frecuente\", \"Obligatorio\" y \"Ocasional\". Elimina pues los registros con frecuencia Muy poco frecuente y Excluyente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3211473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_data_by_frecuency(data):\n",
    "    \n",
    "   \n",
    "    data=data[(data['Frecuencia']==\"Muy frecuente (99-80%)\") |\n",
    "              (data['Frecuencia']==\"Frecuente (79-30%)\") |\n",
    "              (data['Frecuencia']==\"Obligatorio (100%)\") |\n",
    "              (data['Frecuencia']==\"Ocasional (29-5%)\") |\n",
    "              (data['Frecuencia']==\"Muy poco frecuente (4-1%)\")\n",
    "              \n",
    "             ]\n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba84902",
   "metadata": {},
   "source": [
    "# 4. DATA/MATRIX functions  for recommender\n",
    "\n",
    "_rename_col: Función privada que, dado un dataframe con un conjunto de columnas, modifica el nombre de dichas columnas para poder trabajar con su Id, en lugar de literales.\n",
    "Es usada por la función generate_data_scoring para la construcción de la matriz de scoring\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dba0e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rename_col(df):\n",
    "    \n",
    "    df.rename(columns={'Sintoma':'Enfermedades'},\n",
    "               inplace=True)\n",
    "    columnas=len(df.columns)\n",
    "    i=0\n",
    "    while (i<columnas):\n",
    "        df = df.rename(columns={df.columns[i]:i})\n",
    "        i=i+1\n",
    "        \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006013c",
   "metadata": {},
   "source": [
    "\n",
    "generate_data_scoring: Función que dado un dataframe de entrada (con todas los registros existentes entre enfermedades, sus síntomas y la frecuencia de aparición), genera una matriz de enfermedades x sintomas, formada por valores únicamente en celdas donde un síntoma concreto (columna) aparezca en la enfermedad. El valor que tendrá dependerá de la frecuencia de aparición de dicho síntoma en la enfermedad (puntos) de tal forma que si es una frecuencia alta la aparición del síntoma en la enfermedad, tendrá más puntuación que una frecuencia más baja. \n",
    "Se persigue con esto disponer de una matriz de puntuaciones/ratings donde cruzamos todos los síntomas con todas las enfermedades, con un conjunto de puntuaciones. \n",
    "stas son las puntuaciones de acuerdo a la existencia de un síntoma en una enfermedad: \"Muy frecuente\"=3,\n",
    "#\"Frecuente\"=2, \"Obligatorio\"=4 y \"Ocasional\"=1. El resto de celdas tendrá un valor 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7ec4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_scoring (data, repeticiones):\n",
    "    \n",
    "    sintomas=data.iloc[:,1]\n",
    "    sintomas_sin_repe=sintomas.drop_duplicates()\n",
    "    sintomas_sin_repe=sintomas_sin_repe.sort_values(ascending\n",
    "                              = True)\n",
    "    df_scoring=pd.DataFrame(columns=sintomas_sin_repe)\n",
    "  \n",
    "    data_agrupado = (data.groupby(\"Enfermedad\")\n",
    "         .agg({\"Sintoma\": np.array, \"Frecuencia\": np.array})\n",
    "         .reset_index()\n",
    "         )\n",
    "    \n",
    "    z=0\n",
    "    j=0\n",
    "    while (z<repeticiones):\n",
    "        i=0\n",
    "        for a in data_agrupado[\"Enfermedad\"]:\n",
    "\n",
    "            lst = [0] * ((len(sintomas_sin_repe)))\n",
    "           \n",
    "            df_scoring.loc[len(df_scoring)] = lst    \n",
    "            pos=0\n",
    "            for b in data_agrupado[\"Sintoma\"][i]:\n",
    "               \n",
    "                frecuencia=data_agrupado[\"Frecuencia\"][i][pos]\n",
    "  \n",
    "                if (frecuencia==\"Muy frecuente (99-80%)\"):\n",
    "                        valor_entero=4\n",
    "                elif (frecuencia==\"Frecuente (79-30%)\"):\n",
    "                        valor_entero=3\n",
    "                elif (frecuencia==\"Obligatorio (100%)\"):\n",
    "                    valor_entero=5\n",
    "                elif (frecuencia==\"Ocasional (29-5%)\"):\n",
    "                    valor_entero=2\n",
    "                elif (frecuencia==\"Muy poco frecuente (4-1%)\"):\n",
    "                    valor_entero=1\n",
    "                    \n",
    "                df_scoring[b][j]=valor_entero\n",
    "               \n",
    "                pos=pos+1\n",
    "            j=j+1\n",
    "            i=i+1\n",
    "        z=z+1\n",
    "    df_scoring=_rename_col(df_scoring)\n",
    "    df_scoring=df_scoring.transpose()\n",
    "    \n",
    "    return df_scoring\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4b2e38",
   "metadata": {},
   "source": [
    "generate_data_recommendations: Se encarga de calcular dos matrices de trabajo .La primera de similitud entre los síntomas, y la segunda, que guarda en CSV, la de recomendaciones. Esta última de recomendación será cargada en el momento de calcular una recomendación de enfermedad dado un síntoma.\n",
    "En este experimento, con el objetivo de testear la librería sqlite3 (a parte de guardar en CSV), vamos a guardar la matriz de recomendación en una BBDD, con el objetivo de que esté disponible cuando se quiera hacer un cálculo de recomendación, sin necesidad de calcular la matriz cada vez que queramos trabajar en las recomendaciones.\n",
    "Esta función es comentada con más detalle para su entendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "950c7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_recommendations (ratings_matrix):\n",
    "    #Recibimos la matriz \"ratings_matrix\" que está compuesta por el cruce entre todos los síntomas y todos las\n",
    "    #enfermedades; y que tiene los valores 0 (cuando no hay relación) y 1,2,3 y 4 en función de la frecuencia\n",
    "    #de releación entre el síntoma y la enfermedad. Por ejemplo, si la frecuencia es \"muy frecuente\", vendrá\n",
    "    #con un 4 en la celda de relación entre el síntoma y la enfermedad.\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Ahora calculamos la matriz de la similitud entre síntomas, utilizando la función cosine_similarity (distancia\n",
    "    #del coseno (vectores))\n",
    "   \n",
    "    sim_matrix= sklearn.metrics.pairwise.cosine_similarity(ratings_matrix)\n",
    "    #Ya tenemos la matriz de similitudes. \n",
    "    \n",
    "  \n",
    "    #Ahora ya podemos calcular las recomendaciones. Podemos predecir las enfermedades recomendadas a partir \n",
    "    #de una matriz calculada en donde hay relación entre cada enfermedad y síntoma (con un scoring)\n",
    "  \n",
    "    #Por eso usamos \"ratings_matrix\" que tiene las \"puntuaciones\" entre síntoma y enfermedad y \"sim_matrix\" que\n",
    "    #contiene la similitud entre síntomas.\n",
    "    #Cada rating se multiplica por el factor de similitud del síntoma que dio el rating. \n",
    "    #La predicción final por enfermedad será igual a la suma del peso de los ratings dividido por la “suma ponderada”.\n",
    "    recom_matrix = sim_matrix.dot(ratings_matrix) / np.array([np.abs(sim_matrix).sum(axis=1)]).T\n",
    "    # Producto de Matriz de similitud (sim_matrix) con la matrix inicial (ratings_matrix)\n",
    "    #/ (sumatoria de cada fila de ratings) con Transpuesta\n",
    "    \n",
    "    print (\"matriz de similitudes entre síntomas\")\n",
    "    print (sim_matrix)\n",
    "    print (sim_matrix.shape)\n",
    "    print (\"matriz de recomendaciones entre síntoma y enfermedades\")\n",
    "    print (recom_matrix)\n",
    "    print (recom_matrix.shape)\n",
    "    #Preparamos BBDD\n",
    "    conn = sqlite3.connect('test_database')\n",
    "    c = conn.cursor()\n",
    "    #Hacemos transpose para guardar o dará error en \"demasiadas columnas\" (limitación de sqlite)\n",
    "    recom_matrix=recom_matrix.transpose()\n",
    "    df = pd.DataFrame(recom_matrix)\n",
    "    df.to_sql('scorings_tfm_T', conn, if_exists='replace', index = False)\n",
    "    \n",
    "    #Ya tenemos guardada la matriz de recomendaciones para el uso que necesitemos en el momento de recomendar\n",
    "\n",
    "    #No devolvemos nada. En el momento que se quiera usar la matriz, se cargará de BBDD\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88558bca",
   "metadata": {},
   "source": [
    "generate_data_enfermedades: Función que genera un CSV con todas las enfermedades registradas. Es una función\n",
    "para luego trabajar de forma sencilla con el listado de enfermedades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13c01dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_enfermedades (data):\n",
    "    data=data.groupby ([\"Enfermedad\"]).count().reset_index()\n",
    "    data=data.drop([\"Sintoma\",\"Frecuencia\"], axis=1)\n",
    "    df_Enfermedades=data.reset_index()\n",
    "    return df_Enfermedades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721ecd1",
   "metadata": {},
   "source": [
    "generate_data_sintomas: Función que genera un CSV con todas los síntomas registradas. Es una función\n",
    "para luego trabajar de forma sencilla con el listado de síntomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d20c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_sintomas (data):\n",
    "    data=data.groupby ([\"Sintoma\"]).count().reset_index()\n",
    "    df_Sintomas=data.drop([\"Enfermedad\",\"Frecuencia\"], axis=1)\n",
    "    return df_Sintomas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a953abc5",
   "metadata": {},
   "source": [
    "# 5. Recomendation functions\n",
    "\n",
    "_monta_listado: Función privada que dado un listado de recomendaciones (con scoring), el dataframe de enfermedades-sintomas-frecuencias, el listado de enfermedades y el listado de sintomas, muestra un listado ordenado para sacar una  clasificación visual de enfermedades encontradas con el síntoma, la frecuencia de aparición y su scoring.\n",
    "Es usada tanto para el algortimo de recomendación user based como el de test de pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cf7cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _monta_listado (scoring_enfermedades,id_Sintoma,df_EnfeySinto_cleaned_select_no_id, df_Enfermedades, df_Sintomas):\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    j=0\n",
    "    enfermedades=[]\n",
    "    while (j<len(scoring_enfermedades)):\n",
    "        enfermedad=[]\n",
    "        id_enfermedad=scoring_enfermedades[\"index\"][j]\n",
    "        scoring=scoring_enfermedades[id_Sintoma][j]\n",
    "        \n",
    "        enfermedad.append(id_enfermedad)\n",
    "        \n",
    "       \n",
    "        enfermedad.append(df_Enfermedades[df_Enfermedades[\"index\"]==id_enfermedad][\"Enfermedad\"].values[0])\n",
    "   \n",
    "        enfermedad.append(str(scoring))\n",
    "        lista=df_EnfeySinto_cleaned_select_no_id[df_EnfeySinto_cleaned_select_no_id[\"Enfermedad\"]==\n",
    "                                   df_Enfermedades.loc[id_enfermedad][1]]\n",
    "        lista=lista.reset_index()\n",
    "        sintoma= df_Sintomas.loc[id_Sintoma].Sintoma\n",
    "        enfermedad.append(sintoma)\n",
    "        i=0\n",
    "        while i<len(lista):\n",
    "         \n",
    "            if lista[\"Sintoma\"][i]==sintoma:\n",
    "                enfermedad.append(lista[\"Frecuencia\"][i])\n",
    "            \n",
    "            i=i+1  \n",
    "        j=j+1\n",
    "        enfermedades.append(enfermedad)\n",
    "        df_enfermedades=pd.DataFrame(enfermedades)\n",
    "        \n",
    "    return df_enfermedades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2302c40b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "recommendation_collaborative_filtering_user_based: Función que usa User Based de Collaborative Filtering para obtener una recomendación. Recibe un Síntoma concreto y devuelve un listado de X enfermedades recomendadas (por scoring de mayor a menor). Necesita de forma auxiliar el dataframe de enfermedades-sintomas-frecuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44859cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation_collaborative_filtering_user_based(sintoma, elementos, df_EnfeySinto_cleaned_select_no_id):\n",
    " \n",
    "     #Nos viene el Síntoma en la variable \"sintoma\" (ejemplo \"Cough\") y el número de elementos enfermedades\n",
    "    #que queremos que nos recomiende con ese síntoma. \n",
    "    \n",
    "    #Cogemos los DFs de síntomas y enfermedades\n",
    "    df_sintomas=generate_data_sintomas (df_EnfeySinto_cleaned_select_no_id)\n",
    "    df_enfermedades=generate_data_enfermedades(df_EnfeySinto_cleaned_select_no_id)\n",
    "\n",
    "    #Sacamos el Id del Sintoma (al tener el texto)    \n",
    "    id_sintoma = df_sintomas[df_sintomas['Sintoma'] == sintoma].index.values[0]\n",
    "    \n",
    "    \n",
    "    #Necesitamos, como no, la matriz de recomendaciones. La habíamos guardado en BBDD, cargamos con SQlite\n",
    "    conn = sqlite3.connect('test_database')\n",
    "    c = conn.cursor()\n",
    "    c.execute('''  SELECT * FROM scorings_tfm_T\n",
    "          ''')\n",
    "\n",
    "    #Obtenemos c.fetchall la matriz y montamos dataframe\n",
    "    df_recomendaciones = pd.DataFrame(c.fetchall()) \n",
    "   \n",
    "    #transpose porque hemos tenido que hacer transpose para guardar\n",
    "    df_recomendaciones=df_recomendaciones.transpose()\n",
    "    #ahora la convertimos en array numpy para operar (hacer argsort)\n",
    "    df_recomendaciones=df_recomendaciones.to_numpy()\n",
    "       \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #Con la matrix de recomendaciones (síntomas vs enfermedades) cogemos únicamente el vector de enfermedades\n",
    "    #relacionadas con el síntoma \"id_sintoma\"\n",
    "    #Pero ojo,    hemos cogido un vector de enfermedades ordenadas.\n",
    "    enfermedades=df_recomendaciones.argsort()[id_sintoma]\n",
    "    #\n",
    "    vector_id_enfermedad_scoring=[]\n",
    "    #Inicializamos nuestro vector TOTAL que tendrá las parejas de \"enfermedad\" /scoring de recomendación\n",
    "    #(valor en la matriz recomendaciones)\n",
    "    for i, enfermedad_id in enumerate(enfermedades[-elementos:]):  #Nos cogemos las x primeras enfermedades   \n",
    "        #\n",
    "        vector_enfermedades=[]\n",
    "    #vamos cogiendo cada pareja de id enfermedad y el scoring de recomendación  (la pareja la montamos en un vector=)\n",
    "        vector_enfermedades.append (enfermedad_id)\n",
    "        vector_enfermedades.append (df_recomendaciones[id_sintoma][enfermedad_id])\n",
    "       \n",
    "       \n",
    "        vector_id_enfermedad_scoring.append(vector_enfermedades)  #metemos la pareja en el vector TOTAL\n",
    "      \n",
    "    vector_id_enfermedad_scoring=pd.DataFrame(vector_id_enfermedad_scoring)\n",
    "    #pasamos a data frame y luego montamos con la función interna \"monta_listado\" una visualización mejor.\n",
    "    vector_id_enfermedad_scoring = vector_id_enfermedad_scoring.rename(columns={1:id_sintoma, 0:\"index\"})\n",
    "    \n",
    "    listado_para_visualizar=_monta_listado (vector_id_enfermedad_scoring,id_sintoma,\n",
    "                                            df_EnfeySinto_cleaned_select_no_id,df_enfermedades, df_sintomas)\n",
    "    listado_para_visualizar=listado_para_visualizar.rename(columns={0: \"Id Enfermedad\",1: \"Enfermedad\",\n",
    "                                                                    2: \"Scoring\", 3: \"Síntomas\", 4: \"Frecuencia\"})\n",
    "    listado_para_visualizar=listado_para_visualizar.sort_values(\"Scoring\", ascending=False)\n",
    "    listado_para_visualizar=listado_para_visualizar.reset_index()\n",
    "    listado_para_visualizar.drop(\"index\", axis=1, inplace=True)\n",
    "  \n",
    "    return listado_para_visualizar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6928fa2",
   "metadata": {},
   "source": [
    "recommendation_similitud_entre_usuarios_by_pearson: Función que usa Correlación de Pearson para obtener una recomendación. Recibe un Síntoma concreto y devuelve un listado de X enfermedades recomendadas (por scoring de mayor a menor).\n",
    "Necesita de forma auxiliar el dataframe de enfermedades-sintomas-frecuencias, y la matriz de scoring para cálculos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d817d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation_by_pearson (df_scoring, sintoma,elementos,df_EnfeySinto_cleaned_select_no_id):\n",
    "    \n",
    "    df_sintomas=generate_data_sintomas (df_EnfeySinto_cleaned_select_no_id)\n",
    "    df_enfermedades=generate_data_enfermedades(df_EnfeySinto_cleaned_select_no_id)\n",
    "    id_sintoma = df_sintomas[df_sintomas['Sintoma'] == sintoma].index.values[0]\n",
    "\n",
    "    \n",
    "    \n",
    "    df_transpuesta=df_scoring.transpose()\n",
    "    correlaciones = df_transpuesta.corr(method='pearson')\n",
    "\n",
    "    MediasUsers = df_transpuesta.mean(numeric_only=True,skipna=True)\n",
    "    DesviacionesUsers = df_transpuesta.std(numeric_only=True,skipna=True)\n",
    "    df_ValoracionesNorm = df_transpuesta[MediasUsers.index].sub(MediasUsers, axis='columns')\n",
    "\n",
    "    df_ValoracionesNorm = df_ValoracionesNorm.div(DesviacionesUsers, axis='columns')\n",
    "\n",
    "    Numerador = df_ValoracionesNorm.dot(correlaciones)\n",
    "    Numerador.sort_values(0,ascending=False)\n",
    "    Denominador = correlaciones.abs().sum()\n",
    "    Cociente = Numerador.div(Denominador, axis='columns')\n",
    "\n",
    "    Valoraciones = Cociente.mul(DesviacionesUsers,axis='columns').add(MediasUsers, axis='columns')\n",
    "\n",
    "    a=Valoraciones[id_sintoma].sort_values(ascending=False).head(elementos)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    vector=pd.DataFrame(a)\n",
    "    vector=vector.reset_index()\n",
    "    listado_para_visualizar=_monta_listado (vector,id_sintoma, df_EnfeySinto_cleaned_select_no_id,\n",
    "                                            df_enfermedades, df_sintomas)\n",
    "    listado_para_visualizar=listado_para_visualizar.rename(columns={0: \"Id Enfermedad\", 1: \"Enfermedad\",\n",
    "                                                                    2: \"Scoring\", 3: \"Síntomas\", 4: \"Frecuencia\"})\n",
    "    listado_para_visualizar=listado_para_visualizar.sort_values(\"Scoring\", ascending=False)\n",
    " \n",
    "    return listado_para_visualizar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d027c06e",
   "metadata": {},
   "source": [
    "# 6. Notebook Main\n",
    "\n",
    "## Common Tasks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4f3f17",
   "metadata": {},
   "source": [
    "Vayamos por pasos:\n",
    "\n",
    "Se comienza con la lectura del fichero XML fuente de Orphadata, llamando a la función definida anteriormente. Este fichero puede ser descargado aquí: https://drive.google.com/file/d/1ErL1M0OgDE_fkhXeKlaFHw6zvbh5gkN2/view?usp=drive_link (tienen permisos para descarga los tutores del TFM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66433999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.41 s, sys: 54 ms, total: 2.46 s\n",
      "Wall time: 2.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_EnfeySinto=import_enfermedades_xml(\"../data/01_raw/enfermedades.xml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bca3cc8",
   "metadata": {},
   "source": [
    "A modo visual, vemos qué hemos obtenido de esta lectura, tanto a nivel de Enfermedades, como síntomas y frecuencias de aparición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "995f4af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de Lectura del XML Fuente Orphadata\n",
      "Enfermedades:  4262\n",
      "Sintomas:  8303\n",
      "Frecuencias:  6\n"
     ]
    }
   ],
   "source": [
    "print(\"Datos de Lectura del XML Fuente Orphadata\")\n",
    "print(\"Enfermedades: \", df_EnfeySinto[\"Enfermedad\"].nunique())\n",
    "print(\"Sintomas: \", df_EnfeySinto[\"Sintoma\"].nunique())\n",
    "print(\"Frecuencias: \", df_EnfeySinto[\"Frecuencia\"].nunique())  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b2b16",
   "metadata": {},
   "source": [
    "Este es el aspecto que tiene este Dataframe de Enfermedades, los síntomas que tiene, y la frecuencia de aparición. Utilizamos el Id_Enfermedad para visualizar que está cogiendo bien la agrupaciónd de enfermedades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29ba835d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_Enfermedad</th>\n",
       "      <th>Enfermedad</th>\n",
       "      <th>Sintoma</th>\n",
       "      <th>Frecuencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Enfermedad de Alexander</td>\n",
       "      <td>Macrocephaly</td>\n",
       "      <td>Muy frecuente (99-80%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Enfermedad de Alexander</td>\n",
       "      <td>Intellectual disability</td>\n",
       "      <td>Muy frecuente (99-80%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Enfermedad de Alexander</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>Muy frecuente (99-80%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Enfermedad de Alexander</td>\n",
       "      <td>Spasticity</td>\n",
       "      <td>Muy frecuente (99-80%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Enfermedad de Alexander</td>\n",
       "      <td>Agenesis of corpus callosum</td>\n",
       "      <td>Muy frecuente (99-80%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112684</th>\n",
       "      <td>4263</td>\n",
       "      <td>Nevo de cabello lanoso</td>\n",
       "      <td>Brachydactyly</td>\n",
       "      <td>Ocasional (29-5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112685</th>\n",
       "      <td>4263</td>\n",
       "      <td>Nevo de cabello lanoso</td>\n",
       "      <td>Widely-spaced incisors</td>\n",
       "      <td>Ocasional (29-5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112686</th>\n",
       "      <td>4263</td>\n",
       "      <td>Nevo de cabello lanoso</td>\n",
       "      <td>Persistent pupillary membrane</td>\n",
       "      <td>Ocasional (29-5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112687</th>\n",
       "      <td>4263</td>\n",
       "      <td>Nevo de cabello lanoso</td>\n",
       "      <td>Enlarged vestibular aqueduct</td>\n",
       "      <td>Ocasional (29-5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112688</th>\n",
       "      <td>4263</td>\n",
       "      <td>Nevo de cabello lanoso</td>\n",
       "      <td>Precocious puberty</td>\n",
       "      <td>Muy poco frecuente (4-1%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112689 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id_Enfermedad               Enfermedad                        Sintoma  \\\n",
       "0                   0  Enfermedad de Alexander                   Macrocephaly   \n",
       "1                   0  Enfermedad de Alexander        Intellectual disability   \n",
       "2                   0  Enfermedad de Alexander                        Seizure   \n",
       "3                   0  Enfermedad de Alexander                     Spasticity   \n",
       "4                   0  Enfermedad de Alexander    Agenesis of corpus callosum   \n",
       "...               ...                      ...                            ...   \n",
       "112684           4263   Nevo de cabello lanoso                  Brachydactyly   \n",
       "112685           4263   Nevo de cabello lanoso         Widely-spaced incisors   \n",
       "112686           4263   Nevo de cabello lanoso  Persistent pupillary membrane   \n",
       "112687           4263   Nevo de cabello lanoso   Enlarged vestibular aqueduct   \n",
       "112688           4263   Nevo de cabello lanoso             Precocious puberty   \n",
       "\n",
       "                       Frecuencia  \n",
       "0          Muy frecuente (99-80%)  \n",
       "1          Muy frecuente (99-80%)  \n",
       "2          Muy frecuente (99-80%)  \n",
       "3          Muy frecuente (99-80%)  \n",
       "4          Muy frecuente (99-80%)  \n",
       "...                           ...  \n",
       "112684          Ocasional (29-5%)  \n",
       "112685          Ocasional (29-5%)  \n",
       "112686          Ocasional (29-5%)  \n",
       "112687          Ocasional (29-5%)  \n",
       "112688  Muy poco frecuente (4-1%)  \n",
       "\n",
       "[112689 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_EnfeySinto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d617cad3",
   "metadata": {},
   "source": [
    "Ahora comenzamos a limpiar y ver si podemos mejorar los registros. Son muchos síntomas para menos enfermedades. Aplicamos la función eda_data para limpiar repetidos, nulos y quedarnos con los registros que contienen frecuencias que aparecen más de 50 veces en nuestra data. Lógicamente, es la función que más tarda en ejecutar (5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a9cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_EnfeySinto_cleaned=eda_data(df_EnfeySinto)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6ec2e8",
   "metadata": {},
   "source": [
    "Mejoramos notablemente al visualizar los síntomas. Hemos bajado. Vemos también el aspecto del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a221a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Después de EDA\")\n",
    "print(\"Enfermedades: \", df_EnfeySinto_cleaned[\"Enfermedad\"].nunique())\n",
    "print(\"Sintomas: \", df_EnfeySinto_cleaned[\"Sintoma\"].nunique())\n",
    "print(\"Frecuencias: \", df_EnfeySinto_cleaned[\"Frecuencia\"].nunique())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e7991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EnfeySinto_cleaned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3cc91a",
   "metadata": {},
   "source": [
    "Hay frecuencias que podemos obviar al no ver importante un síntoma por ejemplo que aparezca muy muy poco, aplicamos la función de selección por frecuencia, y vemos el aspecto del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_EnfeySinto_cleaned_select=selection_data_by_frecuency(df_EnfeySinto_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EnfeySinto_cleaned_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd473c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Después de Selection\")\n",
    "print(\"Enfermedades: \", df_EnfeySinto_cleaned_select[\"Enfermedad\"].nunique())\n",
    "print(\"Sintomas: \", df_EnfeySinto_cleaned_select[\"Sintoma\"].nunique())\n",
    "print(\"Frecuencias: \", df_EnfeySinto_cleaned_select[\"Frecuencia\"].nunique())  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce6962b",
   "metadata": {},
   "source": [
    "Por último, eliminamos la columna Id_Enfermedad, la cual estamos usando para que, en la visualización de los DF, chequeemos si las enfermedades se listan correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630df42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EnfeySinto_cleaned_select_no_id=df_EnfeySinto_cleaned_select.drop(\"Id_Enfermedad\", axis=1)\n",
    "df_EnfeySinto_cleaned_select_no_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71d1eef",
   "metadata": {},
   "source": [
    "Vamos a analizar con ProfileReport cómo son los datos de este Dataframe con Enfermedad-Síntoma-Frecuencia. Parece todo normal (no duplicados, no missing cells, etc.), sólo destacando que tenemos una alta cardinalidad de Enfermedad (4182) y Síntoma (483), aún habiendo reducido números (especialmente Síntomas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9701a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df_EnfeySinto_cleaned_select_no_id)\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3dd998",
   "metadata": {},
   "source": [
    "Ya hemos ejecutado las fases 1,2 y 3, con Importaciones de Librerías, Importación del XML (a CSV) y proceso EDA & Feature Engineering. Podemos comenzar a trabajar con funciones propias del recomendador (fases 4 y 5).\n",
    "\n",
    "Es importante quedarnos con este dataframe : df_EnfeySinto_cleaned_select_no_id  pues será utilizado (de forma auxiliar) por los recomendadores (para obtener listado de síntomas, enfermedades y visualización de información)\n",
    "\n",
    "Para empezar, usamos las funciones del apartado 4, y construimos las matrices de scoring, similitud y recomendación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d034f8",
   "metadata": {},
   "source": [
    "## All matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2b273e",
   "metadata": {},
   "source": [
    "### Datos Ratings Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799256b",
   "metadata": {},
   "source": [
    "Para comenzar a trabajar con el recomendador, obtenemos la matriz de scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76167759",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_scoring=generate_data_scoring (df_EnfeySinto_cleaned_select_no_id, 1)\n",
    "df_scoring\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232e0a4",
   "metadata": {},
   "source": [
    "Vamos a analizar esta matriz de Scoring a modo gráfico. Si lanzamos un histograma podemos ver que la mayoría de los valores de celda están en 0 (no hay recomendación) y luego hay un pequeño reparto del resto de \"puntuaciones\"/frecuencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b80375",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_scoring,bins=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5ddc8e",
   "metadata": {},
   "source": [
    "Viendo esta cantidad de 0s en la matriz de scoring, existe una medida que te indica el porcentaje de no recomendaciones (o 0s) que hay. Esta medida se denomina Sparsity. Podemos ver con ella que sólo el 2,89% de los valores no son cero. Es decir sólo tenemos un 2,89% de recomendaciones. Es muy poco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33009ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = float(len(df_scoring.values.nonzero()[0]))\n",
    "sparsity = sparsity / (df_scoring.values.shape[0] * df_scoring.values.shape[1])\n",
    "sparsity = sparsity * 100\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d2bff5",
   "metadata": {},
   "source": [
    "### Similitud y Recomendación matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae38c4f",
   "metadata": {},
   "source": [
    "Vamos a generar las matrices de similitud, y la de recomendación. La de recomendación la guardamos en BBDD para ser utilizada.\n",
    "Hemos hecho un print sencillo para ver cómo son estas dos matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "generate_data_recommendations (df_scoring.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7cb8e8",
   "metadata": {},
   "source": [
    "Ya tenemos la matriz de recomendación, podemos comenzar a hacer recomendaciones.  Primero, para ver el comportamiento de los algoritmos, comenzamos con una llamada con un sólo síntoma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf962ba",
   "metadata": {},
   "source": [
    "## Un sólo síntoma: Colaborative Filtering - User Based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dcd7a0",
   "metadata": {},
   "source": [
    "Hacemos la llamada al recomendador que hemos desarrollado con User Based, indicamos un síntoma (\"Cough\"), y decimos que nos muestre los 10 elementos mejores (ranking de 10 enfermedades). Como hemos comentado usamos df_EnfeySinto_cleaned_select_no_id para uso auxiliar, pero necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb67d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_recomendaciones_by_user_based=recommendation_collaborative_filtering_user_based(\n",
    "    \"Cough\",10,df_EnfeySinto_cleaned_select_no_id)\n",
    "list_recomendaciones_by_user_based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac64612",
   "metadata": {},
   "source": [
    "Ya tenemos un primer ranking, donde vemos la enfermedad, la frecuencia con la que el síntoma introducido aparece en dicha enfermedad, y el scoring que devuelve el algoritmo. \n",
    "Vamos a hacer una pequeña comprobación de que la información es consistente. Comprobamos cómo aparece (si aparece) un síntoma (el que hemos introducido) en una de las enfermedades devueltas en el ranking. Parece ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58af586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EnfeySinto_cleaned_select_no_id[(df_EnfeySinto_cleaned_select_no_id[\"Enfermedad\"]==\"Gripe aviar\") &\n",
    "                     ((df_EnfeySinto_cleaned_select_no_id[\"Sintoma\"]==\"Cough\") )]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e2c6d",
   "metadata": {},
   "source": [
    "## Un sólo síntoma: Correlación de Pearson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9500cb7",
   "metadata": {},
   "source": [
    "El algoritmo User Based, es el algoritmo que usaremos para montar el proyecto en Visual studio y disponibilizar a nivel web vía streamlit. Pero, además de las métricas usadas, quiero ver otro algoritmo, y comparar qué devuelve, ver sus resultados...\n",
    "\n",
    "Hacemos la llamada al recomendador que hemos desarrollado usando Correlación de Pearson (explicado en clase), indicamos un síntoma (\"Cough\"), y decimos que nos muestre los 10 elementos mejores (ranking de 10 enfermedades). Como hemos comentado usamos df_EnfeySinto_cleaned_select_no_id para uso auxiliar, pero necesario. Aquí usamos para el cálculo la matriz de scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44436f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_recomendaciones_by_pearson=recommendation_by_pearson(df_scoring,\"Cough\", 10,df_EnfeySinto_cleaned_select_no_id)\n",
    "list_recomendaciones_by_pearson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f4befd",
   "metadata": {},
   "source": [
    "Perfecto!  vemos que las recomendaciones son bastantes similares, diferentes scorings y \"bailan\" en posición del ranking, pero parece que ambos algoritmos devuelven un ranking muy similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff587210",
   "metadata": {},
   "source": [
    "Pasamos al IDE Visual Studio Code, para llevarnos todo este trabajo y ponerlo en marcha para ejecución: modo Pipelines de ejecución para el procesamiento de los datos y matrices, e interfaz Web para la recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b56dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2beab4f37da7cd4415782296c8eb22a3553443b6202cb34c77e531d87231817b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
